{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90b668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-clip in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from openai-clip) (6.3.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from openai-clip) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-clip) (4.67.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->openai-clip) (0.2.14)\n"
     ]
    }
   ],
   "source": [
    "%pip install openai-clip\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "from PIL import Image\n",
    "import clip\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7f298",
   "metadata": {},
   "source": [
    "## Inputs and loading models for the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd6beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda...\n"
     ]
    }
   ],
   "source": [
    "# === Configuration ===\n",
    "TEXT_PROMPTS = [\n",
    "    \"A cute golden retriever\",\n",
    "    \"A snow-covered mountain peak\",\n",
    "    \"A bright red tomato\"\n",
    "]\n",
    "LEARNING_RATE = 0.05\n",
    "STEPS = 10000  # Same steps as constrained\n",
    "TV_WEIGHT = 1e-4  # Controls how \"smooth\" the image is\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Running on {DEVICE}...\")\n",
    "\n",
    "# === 1. Load CLIP ===\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=DEVICE)\n",
    "\n",
    "# === 2. Helper Functions ===\n",
    "\n",
    "# Total Variation Loss (Force Smoothness)\n",
    "def get_tv_loss(img_tensor):\n",
    "    \"\"\"\n",
    "    Calculates the difference between neighbor pixels.\n",
    "    High value = messy noise. Low value = smooth blobs.\n",
    "    \"\"\"\n",
    "    b, c, h, w = img_tensor.shape\n",
    "    h_tv = torch.pow((img_tensor[:, :, 1:, :] - img_tensor[:, :, :h-1, :]), 2).sum()\n",
    "    w_tv = torch.pow((img_tensor[:, :, :, 1:] - img_tensor[:, :, :, :w-1]), 2).sum()\n",
    "    return h_tv + w_tv\n",
    "\n",
    "# Augmentation Pipeline (Force Robustness)\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "])\n",
    "\n",
    "# Normalization for CLIP\n",
    "normalize = transforms.Normalize(\n",
    "    mean=(0.48145466, 0.4578275, 0.40821073),\n",
    "    std=(0.26862954, 0.26130258, 0.27577711)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2e254",
   "metadata": {},
   "source": [
    "### Image generation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb29a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for: 'A cute golden retriever'\n",
      "Step 0 | Sim Loss: 0.8047 | TV Loss: 0.6033\n",
      "Step 100 | Sim Loss: 0.6377 | TV Loss: 0.2609\n",
      "Step 200 | Sim Loss: 0.6357 | TV Loss: 0.3045\n",
      "Step 300 | Sim Loss: 0.5972 | TV Loss: 0.2762\n",
      "Step 400 | Sim Loss: 0.6113 | TV Loss: 0.2909\n",
      "Step 500 | Sim Loss: 0.5884 | TV Loss: 0.2689\n",
      "Step 600 | Sim Loss: 0.6094 | TV Loss: 0.2897\n",
      "Step 700 | Sim Loss: 0.5811 | TV Loss: 0.3234\n",
      "Step 800 | Sim Loss: 0.5830 | TV Loss: 0.3383\n",
      "Step 900 | Sim Loss: 0.6030 | TV Loss: 0.3078\n",
      "Step 1000 | Sim Loss: 0.5830 | TV Loss: 0.3117\n",
      "Step 1100 | Sim Loss: 0.5869 | TV Loss: 0.2883\n",
      "Step 1200 | Sim Loss: 0.5566 | TV Loss: 0.3122\n",
      "Step 1300 | Sim Loss: 0.5635 | TV Loss: 0.3621\n",
      "Step 1400 | Sim Loss: 0.5742 | TV Loss: 0.3211\n",
      "Step 1500 | Sim Loss: 0.5830 | TV Loss: 0.3922\n",
      "Step 1600 | Sim Loss: 0.5869 | TV Loss: 0.3708\n",
      "Step 1700 | Sim Loss: 0.5859 | TV Loss: 0.3402\n",
      "Step 1800 | Sim Loss: 0.5703 | TV Loss: 0.3628\n",
      "Step 1900 | Sim Loss: 0.5601 | TV Loss: 0.3631\n",
      "Step 2000 | Sim Loss: 0.5659 | TV Loss: 0.3100\n",
      "Step 2100 | Sim Loss: 0.5605 | TV Loss: 0.3377\n",
      "Step 2200 | Sim Loss: 0.5464 | TV Loss: 0.3342\n",
      "Step 2300 | Sim Loss: 0.5664 | TV Loss: 0.4080\n",
      "Step 2400 | Sim Loss: 0.5557 | TV Loss: 0.3588\n",
      "Step 2500 | Sim Loss: 0.5625 | TV Loss: 0.3693\n",
      "Step 2600 | Sim Loss: 0.5581 | TV Loss: 0.3751\n",
      "Step 2700 | Sim Loss: 0.5728 | TV Loss: 0.3421\n",
      "Step 2800 | Sim Loss: 0.5850 | TV Loss: 0.3078\n",
      "Step 2900 | Sim Loss: 0.5400 | TV Loss: 0.3530\n",
      "Step 3000 | Sim Loss: 0.5488 | TV Loss: 0.3249\n",
      "Step 3100 | Sim Loss: 0.5415 | TV Loss: 0.3251\n",
      "Step 3200 | Sim Loss: 0.5503 | TV Loss: 0.3440\n",
      "Step 3300 | Sim Loss: 0.5869 | TV Loss: 0.3251\n",
      "Step 3400 | Sim Loss: 0.5381 | TV Loss: 0.2980\n",
      "Step 3500 | Sim Loss: 0.5742 | TV Loss: 0.3029\n",
      "Step 3600 | Sim Loss: 0.5576 | TV Loss: 0.3388\n",
      "Step 3700 | Sim Loss: 0.5400 | TV Loss: 0.3383\n",
      "Step 3800 | Sim Loss: 0.5610 | TV Loss: 0.3109\n",
      "Step 3900 | Sim Loss: 0.5518 | TV Loss: 0.3340\n",
      "Step 4000 | Sim Loss: 0.5342 | TV Loss: 0.3044\n",
      "Step 4100 | Sim Loss: 0.5537 | TV Loss: 0.3487\n",
      "Step 4200 | Sim Loss: 0.5537 | TV Loss: 0.3818\n",
      "Step 4300 | Sim Loss: 0.5391 | TV Loss: 0.3431\n",
      "Step 4400 | Sim Loss: 0.5576 | TV Loss: 0.3401\n",
      "Step 4500 | Sim Loss: 0.5498 | TV Loss: 0.4028\n",
      "Step 4600 | Sim Loss: 0.5527 | TV Loss: 0.3263\n",
      "Step 4700 | Sim Loss: 0.5610 | TV Loss: 0.2811\n",
      "Step 4800 | Sim Loss: 0.5513 | TV Loss: 0.3544\n",
      "Step 4900 | Sim Loss: 0.5439 | TV Loss: 0.3219\n",
      "Step 5000 | Sim Loss: 0.5293 | TV Loss: 0.4191\n",
      "Step 5100 | Sim Loss: 0.5381 | TV Loss: 0.3513\n",
      "Step 5200 | Sim Loss: 0.5488 | TV Loss: 0.3470\n",
      "Step 5300 | Sim Loss: 0.5576 | TV Loss: 0.3446\n",
      "Step 5400 | Sim Loss: 0.5557 | TV Loss: 0.3361\n",
      "Step 5500 | Sim Loss: 0.5527 | TV Loss: 0.3229\n",
      "Step 5600 | Sim Loss: 0.5801 | TV Loss: 0.3313\n",
      "Step 5700 | Sim Loss: 0.5459 | TV Loss: 0.3100\n",
      "Step 5800 | Sim Loss: 0.5449 | TV Loss: 0.3085\n",
      "Step 5900 | Sim Loss: 0.5332 | TV Loss: 0.3158\n",
      "Step 6000 | Sim Loss: 0.5605 | TV Loss: 0.3808\n",
      "Step 6100 | Sim Loss: 0.5303 | TV Loss: 0.3148\n",
      "Step 6200 | Sim Loss: 0.5620 | TV Loss: 0.3232\n",
      "Step 6300 | Sim Loss: 0.5171 | TV Loss: 0.2812\n",
      "Step 6400 | Sim Loss: 0.5488 | TV Loss: 0.3405\n",
      "Step 6500 | Sim Loss: 0.5459 | TV Loss: 0.3742\n",
      "Step 6600 | Sim Loss: 0.5449 | TV Loss: 0.3419\n",
      "Step 6700 | Sim Loss: 0.5864 | TV Loss: 0.3237\n",
      "Step 6800 | Sim Loss: 0.5474 | TV Loss: 0.3236\n",
      "Step 6900 | Sim Loss: 0.5586 | TV Loss: 0.3717\n",
      "Step 7000 | Sim Loss: 0.5415 | TV Loss: 0.3206\n",
      "Step 7100 | Sim Loss: 0.5420 | TV Loss: 0.2879\n",
      "Step 7200 | Sim Loss: 0.5728 | TV Loss: 0.2708\n",
      "Step 7300 | Sim Loss: 0.5586 | TV Loss: 0.3599\n",
      "Step 7400 | Sim Loss: 0.5884 | TV Loss: 0.2883\n",
      "Step 7500 | Sim Loss: 0.5566 | TV Loss: 0.3246\n",
      "Step 7600 | Sim Loss: 0.5596 | TV Loss: 0.3107\n",
      "Step 7700 | Sim Loss: 0.5664 | TV Loss: 0.3015\n",
      "Step 7800 | Sim Loss: 0.5503 | TV Loss: 0.3283\n",
      "Step 7900 | Sim Loss: 0.5430 | TV Loss: 0.3492\n",
      "Step 8000 | Sim Loss: 0.5518 | TV Loss: 0.3253\n",
      "Step 8100 | Sim Loss: 0.5469 | TV Loss: 0.3337\n",
      "Step 8200 | Sim Loss: 0.5508 | TV Loss: 0.3117\n",
      "Step 8300 | Sim Loss: 0.5527 | TV Loss: 0.2971\n",
      "Step 8400 | Sim Loss: 0.5400 | TV Loss: 0.3067\n",
      "Step 8500 | Sim Loss: 0.5513 | TV Loss: 0.3258\n",
      "Step 8600 | Sim Loss: 0.5693 | TV Loss: 0.3104\n",
      "Step 8700 | Sim Loss: 0.5635 | TV Loss: 0.2863\n",
      "Step 8800 | Sim Loss: 0.5347 | TV Loss: 0.3435\n",
      "Step 8900 | Sim Loss: 0.5591 | TV Loss: 0.3155\n",
      "Step 9000 | Sim Loss: 0.5415 | TV Loss: 0.3614\n",
      "Step 9100 | Sim Loss: 0.5781 | TV Loss: 0.3438\n",
      "Step 9200 | Sim Loss: 0.5620 | TV Loss: 0.3691\n",
      "Step 9300 | Sim Loss: 0.5420 | TV Loss: 0.2982\n",
      "Step 9400 | Sim Loss: 0.5615 | TV Loss: 0.2773\n",
      "Step 9500 | Sim Loss: 0.5747 | TV Loss: 0.3156\n",
      "Step 9600 | Sim Loss: 0.5435 | TV Loss: 0.3321\n",
      "Step 9700 | Sim Loss: 0.5566 | TV Loss: 0.3342\n",
      "Step 9800 | Sim Loss: 0.5220 | TV Loss: 0.3141\n",
      "Step 9900 | Sim Loss: 0.5718 | TV Loss: 0.3176\n"
     ]
    }
   ],
   "source": [
    "def generate_constrained_image(prompt, model_name=\"ViT-B\"):\n",
    "    print(f\"\\n=== Generating for: '{prompt}' with model: {model_name} ===\")\n",
    "    \n",
    "    # Tokenize Text\n",
    "    text_token = clip.tokenize([prompt]).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        text_emb = model.encode_text(text_token)\n",
    "        text_emb = text_emb / text_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Initialize Image\n",
    "    image = torch.full((1, 3, 224, 224), 0.5, device=DEVICE)\n",
    "    image = image + (torch.randn_like(image) * 0.1)\n",
    "    image.requires_grad_(True)\n",
    "\n",
    "    optimizer = Adam([image], lr=LEARNING_RATE)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_image = None\n",
    "\n",
    "    print(f\"Optimizing for: '{prompt}' with {model_name}\")\n",
    "\n",
    "    for step in range(STEPS):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Augmentation\n",
    "        augmented_img = aug_transform(image)\n",
    "        \n",
    "        # CLIP Loss\n",
    "        image_norm = normalize(augmented_img)\n",
    "        img_emb = model.encode_image(image_norm)\n",
    "        img_emb = img_emb / img_emb.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        sim_loss = 1 - torch.cosine_similarity(img_emb, text_emb).mean()\n",
    "        \n",
    "        # TV Loss\n",
    "        tv_loss = get_tv_loss(image) * TV_WEIGHT\n",
    "        \n",
    "        total_loss = sim_loss + tv_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image.data.clamp_(0, 1)\n",
    "            \n",
    "        current_sim_loss = sim_loss.item()\n",
    "        if current_sim_loss < best_loss:\n",
    "            best_loss = current_sim_loss\n",
    "            best_image = image.detach().cpu().clone()\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            print(f\"Step {step} | Sim Loss: {current_sim_loss:.4f} | TV Loss: {tv_loss.item():.4f}\")\n",
    "            \n",
    "    if best_image is not None:\n",
    "        filename = os.path.join(\"results\", \"ViT-B\", f\"constrained_{model_name}_{prompt.replace(' ', '_')}.png\")\n",
    "        out_img = best_image.squeeze()\n",
    "        out_pil = transforms.ToPILImage()(out_img)\n",
    "        out_pil.save(filename)\n",
    "        print(f\"Saved {filename}\")\n",
    "        \n",
    "        # Verify\n",
    "        verify_img = preprocess(Image.open(filename)).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            v_img_feat = model.encode_image(verify_img)\n",
    "            v_img_feat /= v_img_feat.norm(dim=-1, keepdim=True)\n",
    "            final_sim = torch.cosine_similarity(v_img_feat, text_emb).item()\n",
    "        print(f\"Final Similarity: {final_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49306b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in TEXT_PROMPTS:\n",
    "    generate_constrained_image(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec242deb",
   "metadata": {},
   "source": [
    "## Saving the image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
